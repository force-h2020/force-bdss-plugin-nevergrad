{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Material prepared by Enthought\n",
    "\n",
    "![](https://www.the-force-project.eu/content/dam/iwm/the-force-project/images/Force_Logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/facebookresearch/nevergrad/master/TwoPointsDE.gif)\n",
    "\n",
    "Official docs and demos are available on [GitHub](https://github.com/facebookresearch/nevergrad/tree/master/docs).\n",
    "\n",
    "_Note: latest version of `nevergrad` requires `python>=3.6.2` due to dependency on core `typing` library_\n",
    "\n",
    "The [`force-bdss-nevergrad-plugin`](https://github.com/force-h2020/force-bdss-plugin-nevergrad) wraps this optimization engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 things to know about Nevergrad:\n",
    "\n",
    "- Nevergrad is a great tool for gradient-free optimization of generic problems, with the possibility to optimize numerical and categorical values. Users have access to benchmarking tools and many algorithms out of the box.\n",
    "\n",
    "- Nevergrad is great for single objective optimization with “easy” constraints: the parameter space is assumed to violate the constraints on a small part of the search space. This means: no equality constraints, no severe inequality constraints. Of course, we can implement the constraints handling ourselves.\n",
    "\n",
    "- Nevergrad can be used for multiobjective optimization: either by explicit conversion of the MCO problem into a single objective problem (for example, using a weighted approach), or using the neveregrad hypervolume approach. The later one provides automated Pareto-front calculation.\n",
    "\n",
    "- It is relatively easy to have custom search spaces: from standard bounded parameters and categorical values, to variables with logarithmic distribution (useful for ML applications), and user-defined distributions.\n",
    "\n",
    "- Ask-and-tell interface allows us to\n",
    "    - Yield the optimization results at runtime when a new input point is explored, and process them if we want to, and\n",
    "    - Instead of using the internal nevergrad’s recommendation system for search space exploration, we can choose what combinations of parameters to explore, and Nevergrad will infer from that.\n",
    "\n",
    "- Nevergrad can, and we should learn how to, do parallel optimization (using multiple “workers”), and GPUs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nevergrad as ng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic usage\n",
    "\n",
    "We create a simple function with one minimum at $x = 1.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x, y=12):\n",
    "    \"\"\"\n",
    "    Convex objective function\n",
    "    \"\"\"\n",
    "    return sum((x - 1.5) ** 2) + abs(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's optimize (minimize) the function value with respect to the function `args`. \n",
    "We will search an $x$ that minimizes the objective function `square(x, y=12)`.\n",
    "\n",
    "We can access the optimizer classes at `ng.optimizers.<optimizer_name>` or via registry: `ng.optimizers.registry[\"optimizer_name\"]`.\n",
    "\n",
    "`OnePlusOne` is one of the supported optimizers in `nevergrad`.\n",
    "\n",
    "MWE of an optimizer: \n",
    "\n",
    "- `instrumentation: int`: with an argument of type `int` defines the dimension of the input search space.\n",
    "\n",
    "- `budget: int`: defines the allowed number of objective evaluations\n",
    "\n",
    "The `x` variable can be a vector of dimension `x_dimension`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dimension = 2\n",
    "\n",
    "optimizer = ng.optimizers.OnePlusOne(instrumentation=x_dimension, budget=100)\n",
    "recommendation = optimizer.minimize(square)\n",
    "\n",
    "print(f\"Recommendation arguments: {recommendation.args}\")\n",
    "print(f\"Recommendation keyword arguments: {recommendation.kwargs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the official documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(optimizer.minimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrumentation: dealing with generic input data\n",
    "\n",
    "It is possible to define an input parameter space tailored for your needs.\n",
    "\n",
    "Whether your objective uses numerical or categorical values, `nevergrad` can do that for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `Scalar` variables\n",
    "\n",
    "Initializing `ng.var.Scalar` variable with normal gaussian prior $\\mathcal{N}\\left(0, 1\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_variable = ng.var.Scalar()\n",
    "print(f\"scalar variable: {scalar_variable.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `Array` variables\n",
    "\n",
    "In fact, `Scalar` is a special one dimensional case of an `Array` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_variable = ng.var.Array(2, 2)\n",
    "print(f\"Array variable: {array_variable.name}\")\n",
    "print(f\"Array dimension: {array_variable.dimension}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using transformations\n",
    "\n",
    "`affined` is one of the transformations we can apply to our variables.\n",
    "\n",
    "- `affined_variable` with gaussian prior $\\mathcal{N}\\left(b, a\\right)$\n",
    "\n",
    "*reminder*: affined transformation is $x \\to a x + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming X -> a*X + b\n",
    "a = 2.0\n",
    "b = -1.0\n",
    "\n",
    "affined_variable = ng.var.Scalar().affined(a=a, b=b)\n",
    "print(f\"scalar variable with affined transformation: {affined_variable.name}\")\n",
    "\n",
    "sample_value = [0.0]\n",
    "print(f\"internal value {sample_value} to user value: {affined_variable.data_to_arguments(sample_value)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bounded` transformation adds lower and upper bounds to a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = 5.0\n",
    "high = 10.0\n",
    "bounded_variable = ng.var.Scalar().bounded(low, high, transform=\"clipping\")\n",
    "\n",
    "print(f\"bounded_variable: {bounded_variable.name}\")\n",
    "print(f\"internal value {high+1.0:4} to user value: {bounded_variable.data_to_arguments([high+1.0])}\")\n",
    "print(f\"internal value {low-1.0:4} to user value: {bounded_variable.data_to_arguments([low-1.0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can stack `transformations` in any order you like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Supplementary material_\n",
    "\n",
    "`nevergrad` uses specific terms to denote the _user_ - level variables (\"arguments\") and _internal_ variables (\"data\"). \n",
    "\n",
    "An example of how they are related:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = [4.0]\n",
    "print(f\"'arguments' {value} to 'data' for `scalar_variable`: \", scalar_variable.arguments_to_data(value))\n",
    "print(f\"'data' {value} to 'arguments' for `scalar_variable`: \", scalar_variable.data_to_arguments(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"'arguments' {value} to 'data' for `affined_scalar_variable`: \", affined_variable.arguments_to_data(value))\n",
    "print(f\"'data' {value} to 'arguments' for `affined_scalar_variable`: \", affined_variable.data_to_arguments(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using discrete variables\n",
    "\n",
    "Dealing with discrete variables was one of the most useful features of `nevergrad` for the Force-BDSS optimizer.\n",
    "\n",
    "From the [official documentation](https://github.com/facebookresearch/nevergrad/blob/faef5c028d6f31ba20a8a88c316ddd1ff4fb4baf/nevergrad/instrumentation/discretization.py#L13),\n",
    "\n",
    "```\n",
    "Nevergrad, in the most fundamental layer, uses continuous variables only.\n",
    "Discrete variables are handled in one of the following ways:\n",
    "- by a softmax transformation, a k-valued categorical variable is converted into k continuous variables.\n",
    "- by a discretization - as we often use Gaussian random values, we discretize according to quantiles \n",
    "of the normal distribution.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `OrderedDiscrete`\n",
    "\n",
    "From the [official documentation](https://github.com/facebookresearch/nevergrad/blob/master/docs/instrumentation.md#variables):\n",
    "\n",
    "```\n",
    "OrderedDiscrete(items): converts a list of (ordered) discrete items into a 1-dimensional variable. \n",
    "The returned value will depend on the value on this dimension: low values corresponding to first elements of the list, and high values to the last.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_data = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "ordered_discrete = ng.var.OrderedDiscrete(ordered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting from the user arguments space to the internal data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for parameter in ordered_data:\n",
    "    print(f\"'arguments' = {parameter} to 'data': {ordered_discrete.arguments_to_data(parameter)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Note_\n",
    "\n",
    "In current version of `nevergrad`, the `OrderedDiscrete` and `UnorderedDiscrete` variables are equivalent:\n",
    "\n",
    "```\n",
    "class OrderedDiscrete(UnorderedDiscrete):\n",
    "    pass\n",
    "```\n",
    "\n",
    "Looking forward to the next release!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Supplementary material_\n",
    "\n",
    "Conversion from the internal data space to user arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ordered_discrete.dimension = {ordered_discrete.dimension}\")\n",
    "\n",
    "for data_value in (-2.0, -0.7, 0.25, 0.7, 2.0):\n",
    "    print(f\"internal value ({data_value:4}) to user value: {ordered_discrete.data_to_arguments([data_value])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SoftmaxCategorical`\n",
    "\n",
    "[Softmax function](https://en.wikipedia.org/wiki/Softmax_function) normalizes an input vector into a probability distribution:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/bdc1f8eaa8064d15893f1ba6426f20ff8e7149c5)\n",
    "\n",
    "From the [official documentation](https://github.com/facebookresearch/nevergrad/blob/master/docs/instrumentation.md#variables):\n",
    "```\n",
    "SoftmaxCategorical(items): converts a list of n (unordered) categorial items into an n-dimensional \n",
    "space. \n",
    "The returned element will be sampled as the softmax of the values on these dimensions. \n",
    "Be cautious: this process is non-deterministic and makes the function evaluation noisy.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_data = [\"x\", \"y\", \"z\"]\n",
    "\n",
    "softmax_discrete = ng.var.SoftmaxCategorical(softmax_data)\n",
    "print(f\"softmax_discrete.dimension = {softmax_discrete.dimension}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion from the internal data space to user arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"internal value = [100, 1, 1] to user value: {softmax_discrete.data_to_arguments([100, 1, 1])}\")\n",
    "print(f\"internal value = [1, 100, 1] to user value: {softmax_discrete.data_to_arguments([1, 100, 1])}\")\n",
    "print(f\"internal value = [1, 1, 100] to user value: {softmax_discrete.data_to_arguments([1, 1, 100])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Supplementary material_\n",
    "\n",
    "Converting from the user arguments space to the internal data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in softmax_data:\n",
    "    print(f\"(argument = {parameter}) to data: {softmax_discrete.arguments_to_data(parameter)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Implement a bounded log distributed variable.\n",
    "Consider this to be a classical \"regularization\" parameter used in ML.\n",
    "\n",
    "For example, construct a variable with normal disctribution from $10^{-6}$ to $10^0$ (in log space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assembling `Instrumentation`\n",
    "\n",
    "We use `Instrumentation` to combine several different variables, and create a single search space.\n",
    "\n",
    "From the [official documentation](https://github.com/facebookresearch/nevergrad/blob/master/docs/instrumentation.md):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg1 = ng.var.OrderedDiscrete([\"a\", \"b\"])\n",
    "arg2 = ng.var.SoftmaxCategorical([\"a\", \"c\", \"e\"])  \n",
    "value = ng.var.Scalar().affined(a=2, b=-1)\n",
    "\n",
    "# create the instrumented function\n",
    "# 1st arg. = positional discrete argument\n",
    "# 2nd arg. = positional discrete argument\n",
    "# 3rd arg. is a positional arg. which will be kept constant to \"blublu\"\n",
    "# 4th arg. is a keyword argument with Gaussian prior\n",
    "instrum = ng.Instrumentation(arg1, arg2, \"blublu\", value=value)\n",
    "print(\"Instrumentation dimension: \", instrum.dimension)  # 5 dimensional space\n",
    "\n",
    "\n",
    "print(instrum.data_to_arguments([1, -80, -80, 80, 3]))\n",
    "# prints (args, kwargs): (('b', 'e', 'blublu'), {'value': 7})\n",
    "# b is selected because 1 > 0 (the threshold is 0 here since there are 2 values.\n",
    "# e is selected because proba(e) = exp(80) / (exp(80) + exp(-80) + exp(-80))\n",
    "# value=7 because 3 * std + mean = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunction(arg1, arg2, arg3, value=10):\n",
    "    penalty = 1.0 if arg1 != arg2 else 0.0\n",
    "    # print(arg1, arg2, arg3, value, value**2 + penalty)\n",
    "    return value**2 + penalty\n",
    "\n",
    "optimizer = ng.optimizers.RandomSearch(instrumentation=instrum, budget=100)\n",
    "recommendation = optimizer.minimize(myfunction)\n",
    "print(recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Ask and Tell\"\n",
    "\n",
    "From the [official documentation](https://github.com/facebookresearch/nevergrad/blob/master/docs/optimization.md#ask-and-tell-interface):\n",
    "\n",
    "An ask and tell interface is also available. The three key methods for this interface are:\n",
    "\n",
    "`ask`: suggest a candidate on which to evaluate the function to optimize.\n",
    "\n",
    "`tell`: for updated the optimizer with the value of the function for a candidate.\n",
    "\n",
    "`provide_recommendation`: returns the candidate the algorithms considers the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x, y=12):\n",
    "    \"\"\"\n",
    "    Convex objective function\n",
    "    \"\"\"\n",
    "    return sum((x - 1.5) ** 2) + abs(y)\n",
    "\n",
    "instrum = ng.Instrumentation(ng.var.Array(2), y=ng.var.Scalar())\n",
    "optimizer = ng.optimizers.OnePlusOne(instrumentation=instrum, budget=100)\n",
    "\n",
    "for _ in range(optimizer.budget):\n",
    "    x = optimizer.ask()\n",
    "    value = square(*x.args, **x.kwargs)\n",
    "    optimizer.tell(x, value)\n",
    "\n",
    "\n",
    "recommendation = optimizer.provide_recommendation()\n",
    "print(recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
